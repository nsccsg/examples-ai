#!/bin/sh

### Run in the shared test and development area
### Note that you do not have exclusive access to the GPUs in the dgx-dev queue
#PBS -q dgx
#PBS -l select=1:ncpus=5:ngpus=1
#PBS -l walltime=1:00:00

### Specify project code
### e.g. 41000001 was the pilot project code
### Job will not submit unless this is changed
#PBS -P 99999999

### Specify name for job
#PBS -N connect

### Standard output by default goes to file $PBS_JOBNAME.o$PBS_JOBID
### Standard error by default goes to file $PBS_JOBNAME.e$PBS_JOBID
### To merge standard output and error use the following
#PBS -j oe

### Start of commands to be run

# Change directory to where job was submitted
cd $PBS_O_WORKDIR || exit $?

# Docker image to use for container
#   To see available images run command: nscc-docker images
#   If image is not present, email help@nscc.sg to request pulling image into repository on all DGX nodes
image="nvcr.io/nvidia/pytorch:latest"

# Use the same port number as your uid
port=$UID

# Run using host networking so that it is easier to access the port
# Modify port value if it clashes with other users
nscc-docker run --net=host $image << EOF > stdout.$PBS_JOBID 2> stderr.$PBS_JOBID
# We can do the following if using "<<EOF" to pass variable as it is expanded by the job shell
cd $PBS_O_WORKDIR
hostname
#
# print out environment variables which need to be manually set in ssh session
#  inside ssh session do ". env.sh"
env | sed -e 's/^/export /' -e 's/=/="/' -e 's/$/"/' > env.sh
# launch ssh daemon
./launch-sshd $port

# do work
sleep 900
EOF

### ssh daemon is running inside container
##
## find out where it is running, 
# qstat -wan1
## ssh to port defined in job script on host where is running
# ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -p $port $node
