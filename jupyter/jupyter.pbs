#!/bin/sh

### The following requests all resources on 1 DGX-1 node
#PBS -l select=1:ncpus=40:ngpus=8

### The "select=1" specifies the number of nodes
### The "ncpus=40:ngpus=8" asks for acccess to all 8 GPU cards
### If you request less than 8 GPU then make the ncpus value
###   five times the ngpus value, e.g. select=1:ncpus=5:ngpus=1

### Specify amount of time required
###  Values less than 4 hours go into a higher priority queue
#PBS -l walltime=1:00:00

### Specify DGX queue
#PBS -q dgx

### Specify project code
### 41000001 is the stakeholder pilot users
### 22270170 is for non-stakeholder piot users
#PBS -P 41000001

### Specify name for job
#PBS -N container

### Standard output by default goes to file $PBS_JOBNAME.o$PBS_JOBID
### Standard error by default goes to file $PBS_JOBNAME.e$PBS_JOBID
### To merge standard output and error use the following
#PBS -j oe

### Start of commands to be run

# Docker image to use for container
#   To see available images run command: nscc-docker images
#   If image is not present, email help@nscc.sg to request pulling image into repository on all DGX nodes
image="nscc/local/tensorflow:latest"

# Job should start in your home directory:
pwd
# Change to directory where job was submitted:
cd "$PBS_O_WORKDIR" || exit $?
pwd
# Please note that when you start a Docker container then it will start in a directory defined by the image
# You will also need to change to the correct directory inside the container

# The "nscc-docker run --ports $image" command runs the following Docker command: 
#    nvidia-docker -u $UID:$GID -v /home:/home --rm -i --shm-size=1g --ulimit memlock=-1 --ulimit stack=67108864 -p 8888:8888 -p 5901:5901 $image /bin/sh
# Run VNC server inside container
nscc-docker run --ports $image << EOF > stdout.$PBS_JOBID 2> stderr.$PBS_JOBID
echo Container starts in the directory:
pwd
# We can do the following if using "<<EOF" to pass commands as it is expanded by the job shell
cd $PBS_O_WORKDIR
export PYTHONUSERBASE=/workspace/.local
# Escaping PYTHONUSERBASE in the next line so that it is expanded inside docker and take the value set inside the container
mkdir -p \$PYTHONUSERBASE/bin
export PATH=\$PATH:\$PYTHONUSERBASE/bin
# Install Jupyter inside container
pip install --user -q --no-cache-dir -U jupyter
jupyter notebook --ip=0.0.0.0 --port=8888
EOF

### On local machine use ssh port forwarding to tunnel to DGX (replace X with 1 to 6)
# ssh -L8888:dgx410X:8888 aspire.nscc.sg
### On local machine go to http://localhost:8888 and use token from container
